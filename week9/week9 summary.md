# Chapter 9. 추천시스템
## 1. 추천 시스템의 개요와 배경
### 추천 시스템의 개요
- 지금은 추천 시스템 전성시대
  - 콘텐츠 포털까지 추천 시스템을 통해 사용자의 취향을 이해하고 맞춤 상품과 콘텐츠를 제공해 조금이라도 오래 자기 사이트에 고객을 머무르게 하기 위해 전력을 기울이고 있음
  - 발전하는 추천 엔진으로 인해 더욱 더 많은 수익을 올릴 수 있다는 사실을 알고 있는 주요 업체들은 추천 엔진의 고도화에 큰 비용과 노력을 들이고 있음
- 하나의 콘텐츠를 선택했을 때 선택된 콘텐츠와 연관된 추천 콘텐츠가 얼마나 사용자의 관심을 끌고 개인에게 맞춘 콘텐츠를 추천했는지는 그 사이트의 평판을 좌우하는데 매우 중요한 요소
- 추천 시스템의 진정한 묘미 : 사용자 자신도 좋아하는지 몰랐던 취향을 시스템이 발견하고 그에 맞는 콘텐츨르 추천해주는 것

### 온라인 스토어의 필수 요소, 추천 시스템
- 추천 시스템은 특히 온라인에서 그 진가를 발휘함
- 좋은 추천 시스템 : 사용자가 무엇을 원하는지 빠르게 찾아내 사용자의 온라인 쇼핑의 즐거움을 배가함
  - 온라인 스토어에서 추천 시스템은 필수 구성 요소
- 온라인 스토어는 많은 양의 고객과 상품 관련 데이터를 가지고 있음
  - 이 모든 데이터가 사용자가 흥미를 가질 만한 상품을 즉각적으로 추천하는 데 사용됨
    - 사용자가 어떤 상품을 구매했는가?
    - 사용자가 어떤 상품을 둘러보거나 장바구니에 넣었는가?
    - 사용자가 평가한 영화 평점은? 제품 평가는?
    - 사용자가 스스로 작성한 자신의 취향은?
    - 사용자가 무엇을 클릭했는가?
    
### 추천 시스템의 유형
- 추천 시스템의 유형 
  - 콘텐츠 기반 필터링
  - 협업 필터링 방식
    - 최근접 이웃 협업 필터링
    - 잠재 요인 협업 필터링
- 추천 시스템의 초창기에는 콘텐츠 기반 필터링이나 최근접 이웃 기반 협업 필터링이 주로 사용됨
  - 넷플릭스 추천 시스템 경연 대회에서 행렬 분해 기법을 이용한 잠재 요인 협업 필터링 방식이 우승하면서 대부분의 온라인 스토어에서 잠재 요인 협업 필터링 기반의 추천 시스템을 적용
  - 하지만 서비스하는 아이템의 특성에 따라 콘텐츠나 최근접 이웃 기반 협업 필터링을 사용하기도 함
  - 요즘에는 개인화 특성을 좀 더 강화하기 위해서 하이브리드 형식으로 콘텐츠 기반과 협업 기반을 결합해 사용하는 경우도 늘고 있음
  
## 2. 콘텐츠 기반 필터링 추천 시스템
- 콘텐츠 기반 필터링 방식 : 사용자가 특정한 아이템을 매우 선호하는 경우, 그 아이템과 비슷한 콘텐츠를 가진 다른 아이템을 추천하는 방식
  - ex)사용자가 높게 평가한 영화의 콘텐츠를 감안해 이와 적절하게 매칭되는 영화를 추천해줌
  
## 3. 최근접 이웃 협업 필터링
- 협업 필터링 : 친구들에게 물어보는 것과 유사한 방식으로 사용자가 아이템에 매긴 평점 정보나 상품 구매 이력과 같은 사용자 행동 양식만을 기반으로 추천을 수행하는 것
- 협업 필터링의 주요 목표 : 사용자-아이템 평점 매트릭스와 같은 축적된 사용자 행동 데이터를 기반으로 사용자가 아직 평가하지 않은 아이템을 예측 평가하는 것

![image](https://user-images.githubusercontent.com/49123169/77330440-b63e9a00-6d62-11ea-92e1-c292c31531d9.png)

  - 협업 필터링은 사용자가 평가한 다른 아이템을 기반으로 사용자가 평가하지 않은 아이템의 예측 평가를 도출하는 방식
- 협업 필터링 기반의 추천 시스템은 최근접 이웃 방식과 잠재 요인 방식으로 나뉘며 두 방식 모두 사용자-아이템 평점 행렬 데이터에만 의지해 추천을 수행함
  - 협업 필터링 알고리즘에 사용되는 사용자-아이템 평점 행렬에서 행은 개별 사용자, 열은 개별 아이템으로 구성되며 사용자 아이디 행, 아이템 아이디 열 위치에 해당하는 값이 평점을 나타내는 형태가 돼야 함
  - 판다의 pivot_table()과 같은 함수를 이용해 사용자-아이템 평점 행렬 형태로 변경해야 함
  
![image](https://user-images.githubusercontent.com/49123169/77331971-c8b9d300-6d64-11ea-8a47-9708252da870.png)

- 일반적으로 이러한 사용자-아이템 평점 행렬은 많은 아이템을 열로 가지는 다차원 행렬이며 사용자가 아이템에 대한 평점을 매기는 경우가 많지 않기 때문에 희소 행렬 특성을 가지고 있음

- 최근접 이웃 협업 필터링(=메모리 협업 필터링)
  - 사용자 기반(User-User) : 당신과 비슷한 고객들이 다음 상품도 구매했습니다.
    - 사용자 기반 최근접 이웃 방식은 특정 사용자와 유사한 다른 사용자를 TOP-N으로 선정해 이 TOP-N 사용자가 좋아하는 아이템을 추천하는 방식
    - 즉, 특정 사용자와 타 사용자 같의 유사도를 측정한 뒤 가장 유사도가 높은 TOP-N 사용자를 추출해 그들이 선호하는 아이템을 추천하는 것
  - 아이템 기반(Item-Item) : 이 상품을 선택한 다른 고객들은 다음 상품도 구매했습니다.
    - 아이템 기반 최근접 이웃 방식 : 그 명칭이 주는 이미지 때문에 '아이템 간의 속성'이 얼마나 비슷한지를 기반으로 추천하다고 착각할 수 있음
    - 하지만 아이템이 가지는 속성과는 상관없이 사용자들이 그 아이템을 좋아하는지/싫어하는지의 평가 척도가 유사한 아이템을 추천하는 기준이 되는 알고리즘
    - 사용자 기반 최근접 이웃 데이터 세트와 행과 열이 서로 반대(행이 개별 아이템이고 열이 개별 사용자임)
    
- 일반적으로 사용자 기반보다는 아이템 기반 협업 필터링이 정확도가 더 높음
  - 이유 : 비슷한 영를 좋아한다고 해서 사람들의 취향이 비슷하다고 판단하기가 어려운 경우가 많음
  - 그래서 최근접 이웃 협업 필터링은 대부분 아이템 기반의 알고리즘을 적용함
- 코사인 유사도는 추천 시스템의 유사도 측정에 가장 많이 적용됨
  - 추천 시스템에 사용되는 데이터는 다차원 희소 행렬이라는 특징이 있으므로 유사도 측정을 위해 주로 코사인 유사도를 이용함
  
## 4. 잠재 요인 협업 필터링
### 잠재 요인 협업 필터링의 이해
- 잠재 요인 협업 필터링 : 사용자-아이템 평점 매트릭스 속에 숨어 있는 잠재 요인을 추출해 추천 예측을 할 수 있게 하는 기법
  - 행렬분해(Matrix Factorization) : 대규모 다차원 행렬을 SVD와 같은 차원 감소 기법으로 분해하는 과정에서 잠재 요인을 추출함
  - 사용자-아이템 평점 행렬 데이터만을 이용해 말 그래도 '잠재 요인'을 끄집어 내는 것을 의미
  - 잠재요인이 어떤 것인지는 명확히 정의할 수 없음
    - ex)영화 평점 기반의 사용자-아이템 평점 행렬 데이터라면 영화가 가지는 장르별 특성 선호도로 가정할 수 있음
    - 사용자-잠재 요인 행렬은 사용자의 영화 장르에 대한 선호도로, 아이템-잠재 요인 행렬은 영화의 장르별 특성값으로 정의할 수 있음
  - 잠재 요인 협력 필터링 알고리즘의 골자
    - '잠재요인'을 기반으로 다차원 희소 행렬인 사용자-아이템 행렬 데이터를 저차원 밀집 행렬의 사용자-잠재요인 행렬과 아이템-잠재 요인 행렬의 전치 행렬(즉, 잠재요인-아이템 행렬)로 분해
    - 이렇게 분해된 두 행렬의 내적을 통해 새로운 예측 사용자-아이템 평점 행렬 데이터를 만들어서 사용자가 아직 평점을 부여하지 않는 아이템에 대한 예측 평점을 생성하는 것
    
### 행렬 분해의 이해
- 행렬 분해는 다차원의 매트릭스를 저차원 매트릭스로 분해하는 기법
  - 종류 : SVD(Singular Vector Decomposition), NMF(Non-Negative Matrix Factorization) 등
  - Factorization은 우리말로 '인수분해'
    - 인수분해는 일반적으로 하나의 복잡한 다항식을 두 개 이상의 좀 더 단순한 인수의 곱으로 분해하는 것
    - 행렬분해도 이와 다르지 않음
- M개의 사용자 행과 N개의 아이템 열을 가진 평점 행렬 R은 M x N 차원으로 구성되며 행렬 분해를 통해서 
  - 사용자-K 차원 잠재 요인 행렬 P(P는 M x K 차원)
  - K차원 잠재 요인-아이템 행렬 Q.T(Q.T는 K x N 차원)로 분해될 수 있음
  - Q는 아이템-잠재 요인 행렬, Q.T는 Q의 전치 행렬인 잠재 요인-아이템 행렬
  
![image](https://user-images.githubusercontent.com/49123169/77404824-a02de980-6df5-11ea-8de2-62e3762eeccb.png)

- R= P*Q.T
  - M은 총 사용자 수
  - N은 총 아이템 수
  - K는 잠재 요인의 차원 수
  - R은 M X N 차원의 사용자-아이템 평점 행렬
  - P는 사용자와 잠재 요인과의 관계 값을 가지는 M X K 차원의 사용자-잠재 요인 행렬
  - Q는 아이템과 잠재 요인과의 관계 값을 가지는 N X K 차원의 아이템-잠재 요인 행렬
  - Q.T는 Q 매트릭스의 행과 열 값을 교환한 전치 행렬

- R행렬의 u행 사용자와 i열 아이템 위치에 있는 평점 데이터 : r<sub>(u,i)</sub>
  - r<sub>(u,i)</sub>=p<sub>u</sub> * q<sup>t</sup><sub>i</sub>
  - p<sub>u</sub>는 P 행렬에서 u행 사용자의 벡터
  - q<sup>t</sup><sub>i</sub>는 Q행렬의 i행 아이템 벡터의 전치 벡터
- 사용자가 평가하지 않은 아이템에 대한 평점도 잠재 요인으로 분해된 P 행렬과 Q행렬을 이용해 예측할 수있음
  - 사용자- 아이템 평점 행렬의 미정 값을 포함한 모든 평점 값은 행렬 분해를 통해 얻어진 P행렬과 Q.T행렬의 내적을 통해 예측 평점으로 다시 계산할 수 있음
  
- R행렬을 어떻게 P와 Q행렬로 분해?
  - 주로 SVD 방식을 이용함 -> 하지만 SVD는 널 값이 없는 행렬에만 적용할 수있음
  - R 행렬에는 아직 평점이 되지 않은 많은 널 값이 있기 때문에 P와 Q 행렬을 일반적인 SVD 방식으로는 분해할 수 없음
  - 이 때문에 확률적 경사 하강법(SGD)이나 ALS(Alternating Least Squares) 방식을 이용해 SVD 수행

### 확률적 경사 하강법을 이용한 행렬 분해
- 확률적 경사 하강법을 이용한 행렬 분해 방법을 요약
  - P와 Q 행렬로 계산된 예측 R 행렬 값이 실제 R 행렬 값과 가장 최소의 오류를 가질 수 있도록 반복적인 비용 함수 최적화를 통해 P와 Q를 유추해내는 것
- SGD를 이용한 행렬 분해의 전반적인 절차
   1. P와 Q를 임의의 값을 가진 행렬로 설정
   2. P와 Q.T 값을 곱해 예측 R 행렬을 계산하고 예측 R 행렬과 실제 R 행렬에 해당하는 오류 값을 계산
   3. 이 오류 값을 최소화할 수 있도록 P와 Q 행렬을 적절한 값으로 각각 업데이트함
   4. 만족할 만한 오류 값을 가질 때까지 2,3번 작업을 반복하면서 P와 Q 값을 업데이트해 근사화함
   
- 실제 값과 예측값의 오류 최소화와 L2 규제를 고려한 비용 함수식

![image](https://user-images.githubusercontent.com/49123169/77406465-07e53400-6df8-11ea-941d-82e1b2702023.png)

- 일반적으로 사용자-아이템 평점 행렬의 경우 행렬 분해를 위해서 단순히 예측 오류값의 최소화와 학습 시 과적합을 피하기 위해서 규제를 반영한 비용 함수를 적용함
- 그리고 위의 비용 함수를 최소화하기 위해서 새롭게 업데이트 되는 밑의 식을 계산할 수 있음

![image](https://user-images.githubusercontent.com/49123169/77406975-cb660800-6df8-11ea-8b87-5e83e9e03ed3.png)

- 비용 함수식과 업데이트 식의 기초가 의미하는 바
  - p<sub>u</sub> : P 행렬의 사용자 u행 벡터
  - q<sub>i</sub><sup>t</sup> : Q 행렬의 아이템 i행의 전치 벡터
  - r<sub>(u,i)</sub> : 실제 R 행렬의 u행, i열에 위치한 값
  - r<sub>(u,i)</sub><sup>^</sup> : 예측 R<sup>^</sup> 행렬의 u행, i열에 위치한 값. p<sub>u</sub> * q<sub>i</sub><sup>t</sup>로 계산
  - e<sub>(u,i)</sub> : u행, i열에 위치한 실제 행렬 값과 예측 행렬 값의 차이 오류. r<sub>(u,i)</sub> - r<sub>(u,i)</sub><sup>^</sup>로 계산
  - η : sgd 학습률
  - λ : L2 규제 계수
  
- SGD 기반의 행렬 분해 : L2 규제를 반영해 실제 R행렬과 예측 R행렬 값의 차이를 최소화하는 방향성을 가지고 P행렬과 Q행렬에 업데이트 값을 반복적으로 수행하면서 최적화된 예측 R행렬을 구하는 방식

## 6. 아이템 기반 최근접 이웃 협업 필터링 실습
### 아이템 기반 최근접 이웃 협업 필터링으로 개인화된 영화 추천
- 영화 유사도 데이터를 이용해 최근접 이웃 협업 필터링으로 개인에게 최적화된 영화 추천을 구현
- 개인화된 영화 추천의 가장 큰 특징 : 개인이 아직 관람하지 않은 영화를 추천한다는 것
  - 아직 관람하지 않은 영화에 대해서 아이템 유사도와 기존에 관람한 영화의 평점 데이터를 기반으로 해 새롭게 모든 영화의 예측 평점을 계산한 후 높은 예측 평점을 가진 영화를 추천하는 방식
- 아이템 기반의 협업 필터링에서 개인화된 예측 평점 식
 
![image](https://user-images.githubusercontent.com/49123169/77408994-edad5500-6dfb-11ea-8a8f-f364c14dbce0.png)

- 식에 있는 변수의 의미
  - R<sub>u,i</sub><sup>^</sup> : 사용자 u, 아이템 i의 개인화된 예측 평점 값
  - S<sub>i,N</sub> : 아이템 i와 가장 유사도가 높은 TOP-N개 아이템의 유사도 벡터
  - R<sub>u,N</sub> : 사용자 u의 아이템 i와 가장 유사도가 높은 TOP-N개 아이템에 대한 실제 평점 벡터
  - 여기에서 S<sub>i,N</sub>와 R<sub>u,N</sub>에 나오는 N값은 아이템의 최근접 이웃 범위 계수를 의미함
    - 이는 특정 아이템과 유사도가 가장 높은 TOP-N개의 다른 아이템을 추출하는 데 사용됨
  - 먼저 N의 범위에 제약을 두지 않고 모든 아이템으로 가정하고 예측 평점을 구하는 로직을 작성한 뒤에 TOP-N 아이템을 기반으로 협업 필터링을 수행하는 로직으로 변경하겠음
  
## 8. 파이썬 추천 시스템 패키지 - Surprise
### Surprise 패키지 소개
- 파이썬 기반의 추천 시스템 구축을 위한 전용 패키지 중의 하나인 Surprise
- Surprise는 파이썬 기반에서 사이킷런과 유사한 API와 프레임 워크를 제공함
- Surprise의 장점
  - 다양한 추천 알고리즘, 예를 들어 사용자 또는 아이템 기반 최근접 이웃 협업 필터링, SVD,SVD++,NMF 기반의 잠재 요인 협업 필터링을 쉽게 적용해 추천 시스템을 구축할 수 있음
  - Surprise의 핵심 API는 사이킷런의 핵심 API와 유사한 API명으로 작성됐음
