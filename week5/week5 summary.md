## 6. 규제 선형 모델 - 릿지,라쏘,엘라스틱넷
### 규제 선형 모델의 개요
 - 좋은 머신러닝 회귀 모델의 특징 
   - 다항 회귀에서 Degree가 1인 경우 지나치게 예측 곡선을 단순화해 데이터에 적합하지 않는 과소적합 모델
   - Degree 15의 경우, 지나치게 모든 데이터에 적합한 회귀식을 만들기 위해서 다항식이 복잡해지고 회귀 계수가 매우 크게 설정되면서
     평가 데이터 세트에 대해서 형편없는 예측 성능을 보임
   - 회귀 모델은 적절히 데이터에 적합하면서도 회귀 계수가 기하급수적으로 커지는 것을 제어할 수 있어야 함
 - RSS를 최소화하는, 즉 실제 값과 예측 값의 차이를 최소화하는 것만 고려함
   - 학습 데이터에 지나치게 맞추게 되고 최귀 계수가 쉽게 커짐
   - 변동성이 오히려 심해져서 테스트 데이터 세트에서는 예측 성능이 저하되기 쉬웠음
   - 이를 반영해 비용 함수는 학습 데이터의 잔차 오류 값을 최소로 하는 RSS 최소화 방법과 과적합을 방지하기 위해 회귀 계수 값이 커지지 않도록
     하는 방법이 서로 균형을 이뤄야 함
   - 회귀 계수의 크기를 제어해 과적합을 개선하기 위한 비용 함수의 목표
     - Min(RSS(W)+alpha*||W||<sup>2</sup><sub>2</sub>
     - alpha : 학습 데이터 적합 정도와 회귀 계수 값의 크기 제어를 수행하는 튜닝 파라미터
     - 비용 함수의 목표가 최소화하는 W벡터를 찾는 것일 때 alpha가 어떤 역할을 하는지 살펴봐야 함
     - alpha=0(매우 작은 값)이라면 비용 함수 식은 기존과 동일한 Min(RSS(W)+0)이 됨
     - alpha가 무한대라면(또는 매우 큰 값)라면 비용 함수 식은 RSS(W)에 비해 alpha*||W||<sup>2</sup><sub>2</sub> 값이 너무 커지게 되므로
       W 값을 0(또는 매우 작게)으로 만들어야 cost가 최소화되는 비용 함수 목표를 달성할 수 있음
   - alpha 값을 크게 하면 비용 함수는 회귀 계수 W의 값을 작게 해 과적합을 개선할 수 있으며 alpha 값을 작게 하면 회귀 계수 W의 값이 커져도
     어느 정도 상쇄가 가능하므로 학습 데이터 적합을 더 개선할 수 있음
   - alpha를 0에서부터 지속적으로 값을 증가시키면 회귀 계수 값의 크기를 감소시킬 수 있음
     - 규제 : 비용 함수에 alpha 값으로 페널티를 부여해 회귀 계수 값의 크기를 감소시켜 과적합을 개선하는 방식
     - 규제의 구분 : L2 방식, L1 방식
       - L2 규제 : alpha*||W||<sup>2</sup><sub>2</sub>와 같이 w의 제곱에 대해 패널티를 부여하는 방식
         - 릿지 회귀 : L2 규제를 적용한 회귀  
       - L1 규제 : alpha*||W||<sub>1</sub>와 같이 W의 절대값에 대해 패널티를 부여
         - 라쏘 회귀 : L1 규제를 적용한 회귀
         - L1 규제를 적용하면 영향력이 크지 않는 회귀 계수 값을 0으로 변환함

### 릿지 회귀
 - 사이킷런은 Ridge 클래스를 통해 릿지 회귀 구현
 - Ridge 클래스의 주요 생성 파라미터는 alpha이며, 이는 릿지 회귀의 alpha L2 규제 계수에 해당함
 - 릿지 회귀는 alpha 값이 커질수록 회귀 계수 값을 작게 만듦.
 - 릿지 회귀의 경우에는 회귀 계수를 0으로 만들지 않음

### 라쏘 회귀
 - 라쏘 회귀 : W의 절댓값에 패널티를 부여하는 L1 규제를 선형 회귀에 적용한 것
   - L1 규제 : alpha*||W||<sub>1</sub>
   - 라쏘 회귀 비용함수의 목표 : RSS(W)+alpha*||W||<sub>1</sub> 식을 최소화하는 W를 찾는 것
   - L2 규제가 회귀 계수의 크기를 감소시키는데 반해, L1 규제는 불필요한 회귀 계수를 급격하게 감소시켜 0으로 만들고 제거함
 - 사이킷런 Lasso 클래스를 통해 라쏘 회귀를 구현
   - Lasso 클래스의 주요 생성파라미터 : alpha이며, 이는 라쏘 회귀의 alpha L1 규제 계수에 해당
   - alpha의 크기가 증가함에 따라 일부 피처의 회귀 계수는 아예 0으로 바뀌고 있음
   - 회귀 계수가 0인 피처는 회귀 식에서 제외되면서 피처 선택의 효과를 얻을 수 있음

### 엘라스틱넷 회귀
 - 엘라스틱넷 회귀 : L2 규제와 L1 규제를 결합한 회귀
 - 엘라스틱넷 회귀 비용함수의 목표 : RSS(W)+alpha2*||W||<sup>2</sup><sub>2</sub>+alpha1*||W||<sub>1</sub>식을 최소화하는 W를 찾는 것
 - 라쏘 회귀가 서로 상관관계가 높은 피처들의 경우에 이들 중에서 중요 피처만을 셀렉션하고 다른 피처들은 모두 회귀 계수를 0으로 만드는 성향이 강함
   - 이러한 성향으로 인해 alpha값에 따라 회귀 계수의 값이 급격히 변동할 수 있는데 엘라스틱넷 회귀는 이를 완화하기 위해 L2 규제를 라쏘 회귀에 추가한 것
 - 엘라스틱넷 회귀의 단점 : L1과 L2 규제가 결합된 규제로 인해 수행 시간이 상대적으로 오래 걸림
 - 사이킷런 ElasticNet 클래스를 통해서 엘라스틱넷 회귀를 구현함
   - ElasticNet 클래스의 주요 생성 파라미터 : alpha와 l1_ratio
   - ElasticNet 클래스의 alpha는 Ridge와 Lasso 클래스의 alpha값과는 다름
   - 엘라스틱넷의 규제 : a * L1 + b+ L2로 정의될 수 있음
     - a는 L1 규제의 alpha값, b는 L2 규제의 alpha 값
     - ElasticNet 클래스의 alpha 파라미터 값 : a+b
   - ElasticNet 클래스의 l1_ration 파라미터 값 : a/(a+b)
   - l1_ratio가 0이면 a가 0이므로 L2 규제와 동일함
   - l1_ratio가 1이면 b가 0이므로 L1 규제와 동일함


### 선형 회귀 모델을 위한 데이터 변환
